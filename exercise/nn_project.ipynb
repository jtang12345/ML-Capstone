{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn_project.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"HK3FFxBvCanq"},"source":["from __future__ import print_function\n","import os\n","import keras\n","from PIL import Image\n","import tensorflow as tf\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n","from keras.datasets import fashion_mnist\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download data set, import into google drive and unzip it \n","# https://cdn.cs50.net/ai/2020/x/projects/5/gtsrb.zip"],"metadata":{"id":"akoNSGFcI-y1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There are 42 folders inside the gtrsb each one correspoding to the label\n"],"metadata":{"id":"-HupCqZIRLew"}},{"cell_type":"code","metadata":{"id":"SFP9KJ0SEUqx"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = '/content/drive/MyDrive/gtrsb/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jjtKI0fVC66H"},"source":["# use os.listdir('path') to get a list of all names in the 0 dir\n","# use PIL Image.open() to load the image then make it a numpy array\n","def load_data():\n","    images, labels = [], [] \n","    for l in range(0, 43): # iterate over all folders in gtrsb\n","        for i in os.listdir(path + str(l)): #iterate over each image in the directory\n","            img = Image.open(path + str(l) + '/' + i)\n","            img_a = np.array(img)\n","            images.append(img_a)\n","            labels.append(l)\n","    return (images, labels)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images, labels = load_data()\n","x_train, x_test = images[:len(images) - (len(images) / 10)], images[:-(len(images) / 10)]\n","y_train, y_test = labels[:len(labels) - (len(labels) / 10)], images[:-(len(labels) / 10)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"-gmryg-XMlcm","executionInfo":{"status":"error","timestamp":1650044517455,"user_tz":420,"elapsed":331,"user":{"displayName":"Michael Brine","userId":"04374685200782582587"}},"outputId":"2735d639-0297-4ef4-8f43-a126e5a8527b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-c7fe7da039b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-43-64feeadde010>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# iterate over all folders in gtrsb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#iterate over each image in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimg_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/Downloads/gtrsb/0'"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"oA1Rt29JWS1-"}},{"cell_type":"code","source":["# Keras works with floats, so we must cast the numbers to floats\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","# Normalize the inputs so they are between 0 and 1\n","x_train /= 255\n","x_test /= 255\n","# convert class vectors to binary class matrices\n","num_classes = 43\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)"],"metadata":{"id":"12S-2wqGUsqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We will build a model with two hidden layers of size 512\n","# Fully connected inputs at each layer\n","# We will use dropout of .5 to help regularize\n","\n","model_1 = [TODO]\n","model_1.add()\n","model_1.add()\n","model_1.add()\n","model_1.add()\n","model_1.add()\n","# ...."],"metadata":{"id":"T8PMDGEDQGBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Note that this model has a LOT of parameters\n","model_1.summary()"],"metadata":{"id":"TKCUP1P4W9QS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compile the model\n","learning_rate = .001\n","model_1.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(learning_rate=learning_rate),\n","              metrics=['accuracy'])"],"metadata":{"id":"ExzPZd5JW_gi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Finally run the model\n","\n","batch_size = 128  # mini-batch with 128 examples\n","epochs = 30\n","history = model_1.fit(\n","    x_train, y_train,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    verbose=1,\n","    validation_data=(x_test, y_test))"],"metadata":{"id":"7no5g4uNXEZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Score the model\n","score = model_1.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"WL65_YuDXMkx"},"execution_count":null,"outputs":[]}]}