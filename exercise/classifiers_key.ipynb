{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1650048882333,"user":{"displayName":"Michael Brine","userId":"04374685200782582587"},"user_tz":420},"id":"6uz-mgBihrz0"},"outputs":[],"source":["import numpy as np # importing NumPy\n","from sklearn import datasets\n","from sklearn.model_selection import KFold # importing KFold\n","from sklearn.linear_model import LogisticRegression # for Logistic Regression \n","from sklearn.naive_bayes import GaussianNB # for Naive Bayes\n","from sklearn.neighbors import KNeighborsClassifier # for kNN\n","from sklearn.svm import LinearSVC # for linear SVM\n","from sklearn import tree # for dicision tree\n","from sklearn.svm import SVC # for SVM with RBF kernel"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":188,"status":"ok","timestamp":1650048882743,"user":{"displayName":"Michael Brine","userId":"04374685200782582587"},"user_tz":420},"id":"r30-T9ymh2tb"},"outputs":[],"source":["X, y = datasets.load_breast_cancer(return_X_y=True)"]},{"cell_type":"markdown","metadata":{"id":"zW7e01eHjdr6"},"source":["Using k-folds we will 'fold' the data, essentially changing witch data instaces are test/train each loop and average the accuracies of each model"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650048882744,"user":{"displayName":"Michael Brine","userId":"04374685200782582587"},"user_tz":420},"id":"JLwRb3hVjtL8"},"outputs":[],"source":["#intialize a list of lists to hold the accuracies\n","accuracies = [[] for _ in range(6)]"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1650048882744,"user":{"displayName":"Michael Brine","userId":"04374685200782582587"},"user_tz":420},"id":"rhxIqPpvitHC"},"outputs":[],"source":["#Make kfolds\n","kf = KFold()\n","folds = kf.get_n_splits(X)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1898,"status":"ok","timestamp":1650048884640,"user":{"displayName":"Michael Brine","userId":"04374685200782582587"},"user_tz":420},"id":"VXwSqmRNi4iC","outputId":"771a18a3-f38f-4561-bfa4-0ea84f3026cb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}],"source":["#this will loop the above output times\n","# read the sklearn document to see what KFold.split returns\n","for train_i, test_i in kf.split(X):\n","    X_train, X_test = X[train_i], X[train_i]\n","    y_train, y_test = y[train_i], y[train_i]\n","\n","    lr = LogisticRegression()\n","    lr.fit(X_train, y_train)\n","    accuracies[0].append(lr.score(X_test, y_test))\n","\n","    # Naive Bayes\n","    gnb = GaussianNB()\n","    gnb.fit(X_train, y_train)\n","    accuracies[1].append(gnb.score(X_test, y_test))\n","\n","    # KNN\n","    knn = KNeighborsClassifier()\n","    knn.fit(X_train, y_train)\n","    accuracies[2].append(knn.score(X_test, y_test))\n","    \n","\n","    # Linear SVM\n","    #linear_svm = # Use sklearn API for linear SVM (with no options)\n","    linear_svm = LinearSVC()\n","    linear_svm.fit(X_train, y_train)\n","    accuracies[3].append(linear_svm.score(X_test, y_test))\n","\n","    # Decision Tree\n","    dt = tree.DecisionTreeClassifier()\n","    dt.fit(X_train, y_train)\n","    accuracies[4].append(dt.score(X_test, y_test))\n","    \n","    # SVM with rbf kernel\n","    rbf_svm = SVC(kernel='rbf')\n","    rbf_svm.fit(X_train, y_train)\n","    accuracies[5].append(rbf_svm.score(X_test, y_test))\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650048884641,"user":{"displayName":"Michael Brine","userId":"04374685200782582587"},"user_tz":420},"id":"_cYcajzRkMK5","outputId":"e6948804-4ba0-4e2e-e51b-7ba1bf765b28"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average accuracies = [0.9547426257952573, 0.9428822055137844, 0.9455186042028147, 0.8950347021399654, 1.0, 0.9182803161750529]\n","Highest accuracy is 1.0 using Decision Tree\n"]}],"source":["#Average the accuracies over the # of folds\n","avg = [(sum(accuracies[x]) / folds) for x in range(6)]\n","print(\"Average accuracies = \" + str(avg))\n","print(\"Highest accuracy is \" + str(max(avg)) + \" using \", end=\"\")\n","winner = avg.index(max(avg))\n","if winner == 0:\n","    print(\"Logistic Regression\")\n","elif winner == 1:\n","    print(\"Naive Bayes\")\n","elif winner == 2:\n","    print(\"KNN\")\n","elif winner == 3:\n","    print(\"Linear SVM\")\n","elif winner == 4:\n","    print(\"Decision Tree\")    \n","elif winner == 5:\n","    print(\"SVM with RBF kernel\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMxKB0FO8R/7/dP3ZhvI0MU","name":"classifiers_key.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
