{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifiers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uz-mgBihrz0"
      },
      "outputs": [],
      "source": [
        "import numpy as np # importing NumPy\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import KFold # importing KFold\n",
        "from sklearn.linear_model import LogisticRegression # for Logistic Regression \n",
        "from sklearn.naive_bayes import GaussianNB # for Naive Bayes\n",
        "from sklearn.neighbors import KNeighborsClassifier # for kNN\n",
        "from sklearn.svm import LinearSVC # for linear SVM\n",
        "from sklearn import tree # for dicision tree\n",
        "from sklearn.svm import SVC # for SVM with RBF kernel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = datasets.load_breast_cancer(return_X_y=True)"
      ],
      "metadata": {
        "id": "r30-T9ymh2tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using k-folds we will 'fold' the data, essentially changing witch data instaces are test/train each loop and average the accuracies of each model"
      ],
      "metadata": {
        "id": "zW7e01eHjdr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#intialize a list of lists to hold the accuracies\n",
        "accuracies = [[] for _ in range(6)]"
      ],
      "metadata": {
        "id": "JLwRb3hVjtL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make kfolds\n",
        "kf = KFold()\n",
        "folds = kf.get_n_splits(X)"
      ],
      "metadata": {
        "id": "rhxIqPpvitHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this will loop the above output times\n",
        "# read the sklearn document to see what KFold.split returns\n",
        "for train_i, test_i in kf.split(X):\n",
        "    X_train, X_test = X[train_i], X[train_i]\n",
        "    y_train, y_test = y[train_i], y[train_i]\n",
        "\n",
        "    lr = LogisticRegression()\n",
        "    lr.fit(X_train, y_train)\n",
        "    accuracies[0].append(lr.score(X_test, y_test))\n",
        "\n",
        "    # Naive Bayes\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    accuracies[1].append(gnb.score(X_test, y_test))\n",
        "\n",
        "    # KNN\n",
        "    knn = KNeighborsClassifier()\n",
        "    knn.fit(X_train, y_train)\n",
        "    accuracies[2].append(knn.score(X_test, y_test))\n",
        "    \n",
        "\n",
        "    # Linear SVM\n",
        "    #linear_svm = # Use sklearn API for linear SVM (with no options)\n",
        "    linear_svm = LinearSVC()\n",
        "    linear_svm.fit(X_train, y_train)\n",
        "    accuracies[3].append(linear_svm.score(X_test, y_test))\n",
        "\n",
        "    # Decision Tree\n",
        "    dt = tree.DecisionTreeClassifier()\n",
        "    dt.fit(X_train, y_train)\n",
        "    accuracies[4].append(dt.score(X_test, y_test))\n",
        "    \n",
        "    # SVM with rbf kernel\n",
        "    rbf_svm = SVC(kernel='rbf')\n",
        "    rbf_svm.fit(X_train, y_train)\n",
        "    accuracies[5].append(rbf_svm.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXwSqmRNi4iC",
        "outputId": "771a18a3-f38f-4561-bfa4-0ea84f3026cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average the accuracies over the # of folds\n",
        "avg = [(sum(accuracies[x]) / folds) for x in range(6)]\n",
        "print(\"Average accuracies = \" + str(avg))\n",
        "print(\"Highest accuracy is \" + str(max(avg)) + \" using \", end=\"\")\n",
        "winner = avg.index(max(avg))\n",
        "if winner == 0:\n",
        "    print(\"Logistic Regression\")\n",
        "elif winner == 1:\n",
        "    print(\"Naive Bayes\")\n",
        "elif winner == 2:\n",
        "    print(\"KNN\")\n",
        "elif winner == 3:\n",
        "    print(\"Linear SVM\")\n",
        "elif winner == 4:\n",
        "    print(\"Decision Tree\")    \n",
        "elif winner == 5:\n",
        "    print(\"SVM with RBF kernel\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cYcajzRkMK5",
        "outputId": "e6948804-4ba0-4e2e-e51b-7ba1bf765b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracies = [0.9547426257952573, 0.9428822055137844, 0.9455186042028147, 0.8950347021399654, 1.0, 0.9182803161750529]\n",
            "Highest accuracy is 1.0 using Decision Tree\n"
          ]
        }
      ]
    }
  ]
}