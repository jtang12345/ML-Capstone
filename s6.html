<!DOCTYPE html>
<html lang="en">

    <head>
        <meta charset = "UTF-8">
        <meta name = "viewport" content = "width=device-wideth, initial-scale=1.0">
        <title>Session 6</title>

        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,900|
        Source+Sans+Pro:300,900&display=swap">


        <link rel="stylesheet" href="css/courses.css">



    </head>

    <body>



        <header>


            <div class="rectangle">
              <button type="button" class="home_button" onClick="parent.location='index.html'">Home</button>
                <button type="button" class="prev_button" onClick="parent.location='s5.html'">Previous</button>
                <button type="button" class="next_button" onClick="parent.location='s7.html'">Next</button>
            </div>





        </header>


        <div class="content">


        <div class="content_list">

          <ul class="collapsibleList">
              <li class="parent-item">
                <a href="exercises.html">Machine Learning Exercises</a>
              </li>
              <li class="parent-item">
                <a href="s1.html">Session 1: Introduction to Machine Learning</a>
                <ul>
                  <li>Introduction to Machine Learning</li>
                  <li>What is machine learning</li>
                  <li>Influences of Machine Learning</li>
                  <li>Components of Machine Learning</li>
                    <ul>
                      <li>Representation</li>
                      <li>Evaluation</li>
                      <li>Optimization</li>
                    </ul>
                  <li>Types of Machine Learning</li>
                  <li>Challenges of Machine Learning</li>
                  <li>Before starting your own machine learning project</li>
                </ul>
              </li>

              <li class="parent-item">
                  <a href="s2.html">Session 2: Bayesian Decision Theory</a>
                  <ul>
                    <li>What is a Bayesian network?</li>
                    <li>How is a Bayesian network represented?</li>
                    <li>What Directed Acyclic Graphs Tell Us</li>
                    <li>Applications of Bayesian Networks</li>
                  </ul>
              </li>

              <li class="parent-item">
                <a href="s3.html">Session 3: Intro to Supervised Learning</a>
                <ul>
                  <li>Intro to Supervised Learning</li>
                  <li>When to use supervised learning</li>
                  <li>Types of Supervised Learning</li>
                    <ul>
                      <li>Classification</li>
                      <li>Regression</li>
                    </ul>
                  <li>Examples of Supervised Learning Algorithms</li>
                    <ul>
                      <li>Linear Regression</li>
                      <li>Logistic Regression</li>
                      <li>Decision Trees</li>
                      <li>Random Forest Regression</li>
                    </ul>
                </ul>
              </li>

              <li class="parent-item">
                <a href="s4.html">Session 4: Intro to Unsupervised Learning</a>
                <ul>
                  <li>When to use unsupervised learning</li>
                  <li>Types of Unsupervised Learning</li>
                    <ul>
                      <li>Clustering</li>
                      <li>Association</li>
                    </ul>
                  <li>Example of an Unsupervised Learning Algorithm</li>
                    <ul>
                      <li>K-Means Clustering</li>
                    </ul>
                </ul>
              </li>

              <li class="parent-item">
                <a href="s5.html">Session 5: Dimensionality Reduction</a>
                <ul>
                  <li>Intro to Dimensionality Reduction</li>
                  <li>Feature Selection</li>
                  <li>Types of Feature Selection</li>
                    <ul>
                      <li>Wrappers</li>
                      <li>Filters</li>
                      <li>Embedded</li>
                    </ul>
                  <li>Feature Extraction</li>
                  <li>Example of A Feature Extraction Technique</li>
                    <ul>
                      <li>Principal Component Analysis</li>
                    </ul>
                </ul>
              </li>

              <li class="parent-item">
                <a href="s6.html">Session 6: Perceptrons and Neural Networks</a>
                <ul>
                  <li>Influence of Biological Neurons</li>
                  <li>Development of Neural Networks</li>
                  <li>Perceptron</li>
                    <ul>
                      <li>What is a perceptron?</li>
                      <li>Parts of Perceptron</li>
                    </ul>
                  <li>Neural Network</li>
                </ul>
              </li>

              <li class="parent-item">
                <a href="s7.html">Session 7: Deep Learning</a>
                <ul>
                  <li>Deep Learning vs Machine Learning</li>
                  <li>Deep Neural Network</li>
                  <li>Deep Learning</li>
                    <ul>
                      <li>Transfer Learning</li>
                    </ul>
                  <li>Number of Neurons for Each Hidden Layer</li>
                </ul>
              </li>

              <li class="parent-item">
                <a href="s8.html">Session 8: Machine Learning Research Trends</a>
                <ul>
                  <li>Applications of Machine Learning in Various Fields</li>
                  <li>Full-Stack Deep Learning</li>
                  <li>Natural Language Processing</li>
                  <li>Natural Disaster Warning</li>
                  <li>Gaming</li>
                  <li>Resources to Look into Latest Research</li>
                </ul>
              </li>
            </ul>
      </div>

      <!-- <script src="js/CollapsableList.js"></script> -->

      <div class="instruction">

        <h2>Session 6: Perceptrons and Neural Networks</h2>
        <p> <mark>Influence of Biological Neurons</mark></p>
          <ul>
          <li>The idea behind neural networks started from our very
            own biological neurons. However, artificial neural networks
            don’t work exactly the same, and there are a bunch of different
            types of neural networks.</li>
          <li>Biological Neurons are organized in networks of billions of neurons
            and each neuron is connected to thousands of other neurons.
            Neurons are individual cells.</li>
          <li>Key Components:</li>
            <li>Cell body: where nucleus and some
              other components of the cell are located</li>
            <li>Dendrites: branches that receives information from neurons</li>
            <li>Axon: sends information to neurons</li>
            <li>Synapses: sends electrical signals to neurons, which will
              influence the neurons to send out another signal</li>
            </ul>

        <p> <mark>Development of Neural Networks</mark></p>
        <ul>
            <li>1943: First Neural Network Architecture (computational model based on biology)</li>
            <li>Neurophysiologist Warren McCulloch and Mathematician Walter Pitt wrote
              a paper entitled “A Logical Calculus of Ideas Immanent in Nervous Activity”
               and created a computational model, known as an “artificial neuron” that
               acts similarly to biological neurons.</li>
            <li>In an artificial neuron, a certain number of inputs need to be
              active in order to produce an output. If two inputs need to be active,
              then more than two inputs will also produce an output.</li>
            <li>Multiple artificial neurons can be put together to build a network.
              A bunch of  these artificial neurons can be used for computation.
              For example, they can model a logical AND, OR, NOT, as well as an identity function.</li>
            <li>The development of neural networks was on-and-off.</li>
            <li>Before the 1960s, it was already believed that one day we’d
              have machines that could even hold a conversation. But, that didn’t
              happen as not much progress was made.
            <li>During the 1980s, there was interest in neural networks again
              and people began to create other architectures.</li>
            <li>But, in the 1990s, neural networks seemed to work less well
              than the other techniques that were discovered.</li>
            <li>To this day, now that we have lots and lots of data for training,
              additional computing power, and improvements in training algorithms,
              neural networks seem to work the best.</li>
            </ul>

        <p> <mark>Perceptron</mark></p>
        <ul>
          <li>Perceptrons are a single layer neural network, they are one of the
            simplest artificial neural networks.</li>
          <li>In fact, it was one of the earliest examples of supervised learning
            back in 1957 that was created by Frank Rosenblatt.</li>
          <li>A perceptron is composed of a threshold logic unit, or TLU, connected to
            the inputs where the input has an associated weight and a sum of all the
            weighted input will be calculated. Then it uses a step function, and the
            result will be outputted depending on the threshold.</li>
        </ul>
        <img class="unsupervised" src="images/perceptron.png">

        <p> <mark>Neural Network</mark></p>
          <ul>
          <li>A perceptron consists of one layer of TLU, but it is possible to
            have multiple layers connected to each other. Because it contains
            multiple layers, it can produce multiple outputs that classify the inputs.</li>
          <li>Essentially, this multilayer perceptron is a neural network. One layer
            contains the input and then the following layers (however many layers used)
            are TLUs. Lower layers are closest to input and upper layers are closest to
            the output. Each layer with the exception of the output layer has a bias neuron.</li>
          <li>Typically, it is a deep neural network when there are layers hidden deeply.
            This is also where deep learning comes to play.</li>
          </ul>
      </div>


        </div>






    </body>

    <footer>

    </footer>




</html>
